{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38eb784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training samples: 2107\n",
      "Validation samples: 393\n",
      "Test samples: 348\n",
      "Model initialized with 2,798,877 parameters\n",
      "Starting Feature Extraction and Correlation Learning Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=92, pipe_handle=106)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule '__main__' has no attribute 'BrainTumorDataset'\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 517\u001b[39m\n\u001b[32m    514\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Feature correlations saved as: feature_correlations.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 492\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    489\u001b[39m trainer = FeatureExtractionTrainer(model, device)\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m    495\u001b[39m trainer.plot_training_history()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 368\u001b[39m, in \u001b[36mFeatureExtractionTrainer.train\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs)\u001b[39m\n\u001b[32m    364\u001b[39m best_val_accuracy = \u001b[32m0.0\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     train_loss, train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_losses.append(train_loss)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_accuracies.append(train_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 312\u001b[39m, in \u001b[36mFeatureExtractionTrainer.train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    309\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m    310\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    313\u001b[39m     data, targets = data.to(\u001b[38;5;28mself\u001b[39m.device), targets.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:1170\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1163\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/context.py:288\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/popen_fork.py:20\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CorrelationLearningMechanism(nn.Module):\n",
    "    \"\"\"\n",
    "    Correlation Learning Mechanism (CLM) inspired by Wo≈∫niak et al. (2023)\n",
    "    Dynamically filters convolutional layer combinations and evaluates feature correlations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels: int = 4, num_classes: int = 2):\n",
    "        super(CorrelationLearningMechanism, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Multi-scale feature extraction branches\n",
    "        self.branch_configs = self._create_branch_configurations()\n",
    "        \n",
    "        # Dynamic convolutional filter banks\n",
    "        self.conv_filters = nn.ModuleDict()\n",
    "        self._initialize_conv_filters()\n",
    "        \n",
    "        # Correlation learning components\n",
    "        self.correlation_net = CorrelationNetwork(512, 256)  # Adjust dimensions based on your feature size\n",
    "        self.feature_selector = FastCorrelationFeatureSelector(256, 128)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def _create_branch_configurations(self) -> List[Dict]:\n",
    "        \"\"\"Create different branch configurations for dynamic filtering\"\"\"\n",
    "        configs = [\n",
    "            # Branch 1: Standard convolution\n",
    "            {'filters': 32, 'kernel_size': 3, 'pool_type': 'max', 'activation': 'relu'},\n",
    "            # Branch 2: Depth-wise separable convolution\n",
    "            {'filters': 64, 'kernel_size': 5, 'pool_type': 'avg', 'activation': 'relu'},\n",
    "            # Branch 3: Dilated convolution for larger receptive field\n",
    "            {'filters': 32, 'kernel_size': 3, 'dilation': 2, 'pool_type': 'max', 'activation': 'leaky_relu'},\n",
    "            # Branch 4: Asymmetric convolution\n",
    "            {'filters': 64, 'kernel_size': (1, 3), 'pool_type': 'avg', 'activation': 'relu'},\n",
    "        ]\n",
    "        return configs\n",
    "    \n",
    "    def _initialize_conv_filters(self):\n",
    "        \"\"\"Initialize different convolutional filter types\"\"\"\n",
    "        # Standard convolutional layers\n",
    "        self.conv_filters['standard_3x3'] = nn.Conv2d(self.input_channels, 32, 3, padding=1)\n",
    "        self.conv_filters['standard_5x5'] = nn.Conv2d(self.input_channels, 32, 5, padding=2)\n",
    "        \n",
    "        # Depth-wise separable convolutions\n",
    "        self.conv_filters['depthwise_3x3'] = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, self.input_channels, 3, padding=1, groups=self.input_channels),\n",
    "            nn.Conv2d(self.input_channels, 32, 1)\n",
    "        )\n",
    "        \n",
    "        # Dilated convolutions\n",
    "        self.conv_filters['dilated_3x3'] = nn.Conv2d(self.input_channels, 32, 3, padding=2, dilation=2)\n",
    "        \n",
    "        # Asymmetric convolutions\n",
    "        self.conv_filters['asymmetric_1x3'] = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, 32, (1, 3), padding=(0, 1)),\n",
    "            nn.Conv2d(32, 32, (3, 1), padding=(1, 0))\n",
    "        )\n",
    "    \n",
    "    def _apply_dynamic_pooling(self, x: torch.Tensor, pool_type: str) -> torch.Tensor:\n",
    "        \"\"\"Apply dynamic pooling operations\"\"\"\n",
    "        if pool_type == 'max':\n",
    "            return F.adaptive_max_pool2d(x, (x.size(2)//2, x.size(3)//2))\n",
    "        elif pool_type == 'avg':\n",
    "            return F.adaptive_avg_pool2d(x, (x.size(2)//2, x.size(3)//2))\n",
    "        elif pool_type == 'mixed':\n",
    "            max_pool = F.adaptive_max_pool2d(x, (x.size(2)//2, x.size(3)//2))\n",
    "            avg_pool = F.adaptive_avg_pool2d(x, (x.size(2)//2, x.size(3)//2))\n",
    "            return (max_pool + avg_pool) / 2\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def _apply_activation(self, x: torch.Tensor, activation: str) -> torch.Tensor:\n",
    "        \"\"\"Apply dynamic activation functions\"\"\"\n",
    "        if activation == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif activation == 'leaky_relu':\n",
    "            return F.leaky_relu(x, 0.1)\n",
    "        elif activation == 'elu':\n",
    "            return F.elu(x)\n",
    "        elif activation == 'selu':\n",
    "            return F.selu(x)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass through CLM\n",
    "        Returns: tuple of (features, classification_logits)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Extract features using multiple filter configurations\n",
    "        branch_outputs = []\n",
    "        \n",
    "        for name, filter_module in self.conv_filters.items():\n",
    "            # Apply convolutional filter\n",
    "            filtered = filter_module(x)\n",
    "            \n",
    "            # Apply pooling based on filter type\n",
    "            if 'dilated' in name:\n",
    "                pooled = self._apply_dynamic_pooling(filtered, 'max')\n",
    "            elif 'depthwise' in name:\n",
    "                pooled = self._apply_dynamic_pooling(filtered, 'avg')\n",
    "            else:\n",
    "                pooled = self._apply_dynamic_pooling(filtered, 'mixed')\n",
    "            \n",
    "            # Apply activation\n",
    "            if 'leaky' in name:\n",
    "                activated = self._apply_activation(pooled, 'leaky_relu')\n",
    "            else:\n",
    "                activated = self._apply_activation(pooled, 'relu')\n",
    "            \n",
    "            branch_outputs.append(activated)\n",
    "        \n",
    "        # Concatenate all branch outputs\n",
    "        concatenated_features = torch.cat(branch_outputs, dim=1)\n",
    "        \n",
    "        # Apply correlation learning\n",
    "        correlated_features = self.correlation_net(concatenated_features)\n",
    "        \n",
    "        # Apply fast correlation feature selection\n",
    "        selected_features = self.feature_selector(correlated_features)\n",
    "        \n",
    "        # Global average pooling\n",
    "        global_features = F.adaptive_avg_pool2d(selected_features, (1, 1))\n",
    "        global_features = global_features.view(batch_size, -1)\n",
    "        \n",
    "        # Classification\n",
    "        classification_logits = self.classifier(global_features)\n",
    "        \n",
    "        return global_features, classification_logits\n",
    "\n",
    "class CorrelationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network component that evaluates and correlates CNN outputs\n",
    "    to improve feature relevance and classification confidence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels: int, output_channels: int):\n",
    "        super(CorrelationNetwork, self).__init__()\n",
    "        \n",
    "        self.correlation_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 384, 3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, output_channels, 1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism for feature correlation\n",
    "        self.attention = CorrelationAttention(output_channels)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.correlation_layers(x)\n",
    "        correlated_features = self.attention(features)\n",
    "        return correlated_features\n",
    "\n",
    "class CorrelationAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention mechanism that learns correlations between feature maps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super(CorrelationAttention, self).__init__()\n",
    "        \n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, 7, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Channel attention\n",
    "        channel_weights = self.channel_attention(x)\n",
    "        x_channel = x * channel_weights\n",
    "        \n",
    "        # Spatial attention\n",
    "        avg_out = torch.mean(x_channel, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x_channel, dim=1, keepdim=True)\n",
    "        spatial_input = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_weights = self.spatial_attention(spatial_input)\n",
    "        x_spatial = x_channel * spatial_weights\n",
    "        \n",
    "        return x_spatial\n",
    "\n",
    "class FastCorrelationFeatureSelector(nn.Module):\n",
    "    \"\"\"\n",
    "    Fast-correlation filter-based automatic feature selection\n",
    "    Avoids redundancy in features as mentioned in the research\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels: int, output_channels: int):\n",
    "        super(FastCorrelationFeatureSelector, self).__init__()\n",
    "        \n",
    "        self.selector = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels // 2, 1),\n",
    "            nn.BatchNorm2d(input_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(input_channels // 2, output_channels, 1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Learnable feature importance weights\n",
    "        self.feature_importance = nn.Parameter(torch.ones(input_channels))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply feature importance weights\n",
    "        weighted_x = x * self.feature_importance.view(1, -1, 1, 1)\n",
    "        \n",
    "        # Feature selection\n",
    "        selected_features = self.selector(weighted_x)\n",
    "        return selected_features\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    \"\"\"Dataset class for preprocessed brain tumor CT scans\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = \"train\", transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Collect all processed files\n",
    "        self.samples = []\n",
    "        for label in [\"tumor\", \"normal\"]:\n",
    "            label_dir = self.data_dir / split / label\n",
    "            if label_dir.exists():\n",
    "                for file_path in label_dir.glob(\"*.npy\"):\n",
    "                    self.samples.append((file_path, 1 if label == \"tumor\" else 0))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load preprocessed multi-scale data\n",
    "        data = np.load(file_path)  # Shape: (H, W, 4) - multi-channel\n",
    "        data = data.transpose(2, 0, 1)  # Convert to (4, H, W)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        data = torch.FloatTensor(data)\n",
    "        label = torch.LongTensor([label]).squeeze()\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "class FeatureExtractionTrainer:\n",
    "    \"\"\"\n",
    "    Trainer class for the feature extraction and correlation learning step\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: nn.Module, device: torch.device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "        # Loss function with class weighting for imbalance\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=5, factor=0.5)\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "    \n",
    "    def train_epoch(self, train_loader: DataLoader) -> Tuple[float, float]:\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            features, outputs = self.model(data)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_accuracy\n",
    "    \n",
    "    def validate_epoch(self, val_loader: DataLoader) -> Tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                features, outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_accuracy = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_accuracy\n",
    "    \n",
    "    def train(self, train_loader: DataLoader, val_loader: DataLoader, epochs: int = 50):\n",
    "        print(\"Starting Feature Extraction and Correlation Learning Training...\")\n",
    "        \n",
    "        best_val_accuracy = 0.0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc = self.validate_epoch(val_loader)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'  Learning Rate: {self.optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_accuracy:\n",
    "                best_val_accuracy = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_accuracy': val_acc,\n",
    "                }, 'best_clm_model.pth')\n",
    "                print(f'  New best model saved with validation accuracy: {val_acc:.2f}%')\n",
    "            \n",
    "            print('-' * 60)\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(self.train_losses, label='Training Loss')\n",
    "        ax1.plot(self.val_losses, label='Validation Loss')\n",
    "        ax1.set_title('Training and Validation Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(self.train_accuracies, label='Training Accuracy')\n",
    "        ax2.plot(self.val_accuracies, label='Validation Accuracy')\n",
    "        ax2.set_title('Training and Validation Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('clm_training_history.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "def analyze_feature_correlations(model: CorrelationLearningMechanism, dataloader: DataLoader, device: torch.device):\n",
    "    \"\"\"\n",
    "    Analyze feature correlations learned by the CLM\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            features, _ = model(data)\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_labels.append(targets.cpu().numpy())\n",
    "    \n",
    "    all_features = np.vstack(all_features)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    \n",
    "    print(f\"Extracted features shape: {all_features.shape}\")\n",
    "    \n",
    "    # Calculate feature correlations\n",
    "    correlation_matrix = np.corrcoef(all_features.T)\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Feature Index')\n",
    "    plt.savefig('feature_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return all_features, all_labels\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run feature extraction and correlation learning\"\"\"\n",
    "    # Configuration\n",
    "    DATA_DIR = \"/Users/jeissonparra/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/CT_enhanced\"\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 50\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = BrainTumorDataset(DATA_DIR, split=\"train\")\n",
    "    val_dataset = BrainTumorDataset(DATA_DIR, split=\"val\")\n",
    "    test_dataset = BrainTumorDataset(DATA_DIR, split=\"test\")\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Initialize CLM model\n",
    "    model = CorrelationLearningMechanism(input_channels=4, num_classes=2)\n",
    "    print(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = FeatureExtractionTrainer(model, device)\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(train_loader, val_loader, epochs=EPOCHS)\n",
    "    \n",
    "    # Plot training history\n",
    "    trainer.plot_training_history()\n",
    "    \n",
    "    # Analyze feature correlations\n",
    "    print(\"Analyzing feature correlations...\")\n",
    "    features, labels = analyze_feature_correlations(model, val_loader, device)\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    checkpoint = torch.load('best_clm_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    test_loss, test_accuracy = trainer.validate_epoch(test_loader)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Feature Extraction and Correlation Learning completed successfully!\")\n",
    "    print(\"üìä Model saved as: best_clm_model.pth\")\n",
    "    print(\"üìà Training history saved as: clm_training_history.png\")\n",
    "    print(\"üîç Feature correlations saved as: feature_correlations.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
