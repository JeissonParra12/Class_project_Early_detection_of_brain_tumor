{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf500fd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MedicalImagePreprocessor:\n",
    "    \"\"\"\n",
    "    Comprehensive medical image preprocessing pipeline based on research papers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_size=(224, 224)):\n",
    "        self.target_size = target_size\n",
    "        self.quality_metrics = {}\n",
    "        \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load image with error handling\"\"\"\n",
    "        if isinstance(image_path, str):\n",
    "            image_path = Path(image_path)\n",
    "        \n",
    "        try:\n",
    "            # Try multiple color modes\n",
    "            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                image = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
    "                if image is not None:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not load image {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_psnr(self, original, processed):\n",
    "        \"\"\"Calculate PSNR without skimage\"\"\"\n",
    "        if original.shape != processed.shape:\n",
    "            processed = cv2.resize(processed, (original.shape[1], original.shape[0]))\n",
    "            \n",
    "        mse = np.mean((original.astype(float) - processed.astype(float)) ** 2)\n",
    "        if mse == 0:\n",
    "            return float('inf')\n",
    "        return 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "    \n",
    "    def calculate_ssim(self, original, processed):\n",
    "        \"\"\"Simplified SSIM calculation without skimage\"\"\"\n",
    "        if original.shape != processed.shape:\n",
    "            processed = cv2.resize(processed, (original.shape[1], original.shape[0]))\n",
    "            \n",
    "        # Convert to float\n",
    "        original = original.astype(float)\n",
    "        processed = processed.astype(float)\n",
    "        \n",
    "        # Constants for stability\n",
    "        C1 = (0.01 * 255) ** 2\n",
    "        C2 = (0.03 * 255) ** 2\n",
    "        \n",
    "        # Calculate means\n",
    "        mu_x = np.mean(original)\n",
    "        mu_y = np.mean(processed)\n",
    "        \n",
    "        # Calculate variances and covariance\n",
    "        sigma_x = np.var(original)\n",
    "        sigma_y = np.var(processed)\n",
    "        sigma_xy = np.cov(original.flatten(), processed.flatten())[0, 1]\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        numerator = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "        denominator = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "        \n",
    "        return numerator / denominator\n",
    "    \n",
    "    def medical_denoise(self, image):\n",
    "        \"\"\"\n",
    "        Medical-grade denoising based on research papers\n",
    "        \"\"\"\n",
    "        if image.dtype != np.uint8:\n",
    "            image = image.astype(np.uint8)\n",
    "            \n",
    "        # Method 1: Non-local means denoising (from denoising paper)\n",
    "        denoised = cv2.fastNlMeansDenoising(\n",
    "            image, \n",
    "            h=12,  # Filter strength\n",
    "            templateWindowSize=7, \n",
    "            searchWindowSize=21\n",
    "        )\n",
    "        \n",
    "        # Method 2: Median filtering for salt-and-pepper noise\n",
    "        denoised = cv2.medianBlur(denoised, 3)\n",
    "        \n",
    "        # Method 3: Bilateral filtering for edge preservation\n",
    "        denoised = cv2.bilateralFilter(denoised, 5, 75, 75)\n",
    "        \n",
    "        return denoised\n",
    "    \n",
    "    def advanced_contrast_enhancement(self, image):\n",
    "        \"\"\"\n",
    "        Multi-stage contrast enhancement from hybrid learning paper\n",
    "        \"\"\"\n",
    "        if image.dtype != np.uint8:\n",
    "            image = image.astype(np.uint8)\n",
    "            \n",
    "        # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(image)\n",
    "        \n",
    "        # Adaptive gamma correction\n",
    "        mean_intensity = np.mean(enhanced)\n",
    "        gamma = 1.0 - (mean_intensity - 127) / 255 * 0.4  # Adaptive gamma\n",
    "        gamma = max(0.5, min(1.5, gamma))  # Clamp gamma values\n",
    "        \n",
    "        # Build lookup table for gamma correction\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 \n",
    "                         for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        enhanced = cv2.LUT(enhanced, table)\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def extract_brain_region(self, image):\n",
    "        \"\"\"\n",
    "        Simple brain region extraction using thresholding and morphology\n",
    "        \"\"\"\n",
    "        # Otsu's thresholding\n",
    "        _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Morphological operations to clean up\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find largest contour (assumed to be brain)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            mask = np.zeros_like(image)\n",
    "            cv2.drawContours(mask, [largest_contour], -1, 255, -1)\n",
    "            \n",
    "            # Apply mask\n",
    "            result = cv2.bitwise_and(image, image, mask=mask)\n",
    "            return result\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def multi_scale_processing(self, image):\n",
    "        \"\"\"\n",
    "        Multi-scale feature preservation inspired by CLM paper\n",
    "        \"\"\"\n",
    "        # Original resolution processing\n",
    "        original = cv2.resize(image, self.target_size)\n",
    "        \n",
    "        # Downsampled processing for global context\n",
    "        downsampled = cv2.resize(image, (self.target_size[0]//2, self.target_size[1]//2))\n",
    "        downsampled = cv2.resize(downsampled, self.target_size)\n",
    "        \n",
    "        # Edge-enhanced processing\n",
    "        edges = cv2.Canny(image, 30, 100)\n",
    "        edges = cv2.resize(edges, self.target_size)\n",
    "        \n",
    "        # Texture-enhanced processing using gradient\n",
    "        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        texture = np.sqrt(sobelx**2 + sobely**2)\n",
    "        texture = cv2.normalize(texture, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        texture = cv2.resize(texture, self.target_size)\n",
    "        \n",
    "        # Stack all channels\n",
    "        multi_scale = np.stack([original, downsampled, edges, texture], axis=-1)\n",
    "        \n",
    "        return multi_scale\n",
    "    \n",
    "    def calculate_quality_metrics(self, original, processed, image_name):\n",
    "        \"\"\"\n",
    "        Calculate PSNR and SSIM metrics as done in research papers\n",
    "        \"\"\"\n",
    "        if original.shape != processed.shape:\n",
    "            processed_resized = cv2.resize(processed, (original.shape[1], original.shape[0]))\n",
    "        else:\n",
    "            processed_resized = processed\n",
    "            \n",
    "        # Ensure same data type\n",
    "        if original.dtype != processed_resized.dtype:\n",
    "            processed_resized = processed_resized.astype(original.dtype)\n",
    "            \n",
    "        # Calculate metrics using custom functions\n",
    "        psnr = self.calculate_psnr(original, processed_resized)\n",
    "        ssim = self.calculate_ssim(original, processed_resized)\n",
    "        \n",
    "        self.quality_metrics[image_name] = {\n",
    "            'psnr': psnr,\n",
    "            'ssim': ssim\n",
    "        }\n",
    "        \n",
    "        return psnr, ssim\n",
    "    \n",
    "    def comprehensive_preprocessing(self, image_path, save_quality_metrics=True):\n",
    "        \"\"\"\n",
    "        Complete preprocessing pipeline incorporating research findings\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        original_image = self.load_image(image_path)\n",
    "        if original_image is None:\n",
    "            return None\n",
    "        \n",
    "        # Store original for quality metrics\n",
    "        original_copy = original_image.copy()\n",
    "        \n",
    "        # Step 1: Brain region extraction (if applicable)\n",
    "        brain_extracted = self.extract_brain_region(original_image)\n",
    "        \n",
    "        # Step 2: Medical-grade denoising\n",
    "        denoised = self.medical_denoise(brain_extracted)\n",
    "        \n",
    "        # Step 3: Advanced contrast enhancement\n",
    "        enhanced = self.advanced_contrast_enhancement(denoised)\n",
    "        \n",
    "        # Step 4: Multi-scale processing\n",
    "        processed = self.multi_scale_processing(enhanced)\n",
    "        \n",
    "        # Step 5: Normalization\n",
    "        processed = processed.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Calculate quality metrics\n",
    "        if save_quality_metrics:\n",
    "            image_name = Path(image_path).name\n",
    "            psnr, ssim = self.calculate_quality_metrics(original_copy, \n",
    "                                                       (processed[:,:,0] * 255).astype(np.uint8), \n",
    "                                                       image_name)\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def research_augmentation(self, image):\n",
    "        \"\"\"\n",
    "        Research-backed data augmentation techniques\n",
    "        \"\"\"\n",
    "        augmentations = []\n",
    "        \n",
    "        if len(image.shape) == 3:\n",
    "            image = image[:,:,0]  # Use first channel for augmentation\n",
    "        \n",
    "        # Convert to uint8 for OpenCV operations\n",
    "        if image.dtype != np.uint8:\n",
    "            image_uint8 = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_uint8 = image\n",
    "        \n",
    "        # 1. Gaussian noise addition (from denoising paper)\n",
    "        for sigma in [10, 15, 20]:\n",
    "            noise = np.random.normal(0, sigma, image_uint8.shape).astype(np.float32)\n",
    "            noisy_image = image_uint8.astype(np.float32) + noise\n",
    "            noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "            augmentations.append(noisy_image)\n",
    "        \n",
    "        # 2. Rotation with smaller angles for medical images\n",
    "        height, width = image_uint8.shape\n",
    "        for angle in [-10, -5, 5, 10]:\n",
    "            matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, 1.0)\n",
    "            rotated = cv2.warpAffine(image_uint8, matrix, (width, height))\n",
    "            augmentations.append(rotated)\n",
    "        \n",
    "        # 3. Contrast variations (from hybrid learning paper)\n",
    "        for contrast_factor in [0.7, 0.9, 1.1, 1.3]:\n",
    "            contrasted = np.clip(image_uint8.astype(np.float32) * contrast_factor, 0, 255)\n",
    "            augmentations.append(contrasted.astype(np.uint8))\n",
    "        \n",
    "        # 4. Brightness variations\n",
    "        for brightness in [-20, -10, 10, 20]:\n",
    "            brightened = np.clip(image_uint8.astype(np.float32) + brightness, 0, 255)\n",
    "            augmentations.append(brightened.astype(np.uint8))\n",
    "        \n",
    "        # 5. Flip augmentations\n",
    "        augmentations.append(cv2.flip(image_uint8, 0))  # Vertical flip\n",
    "        augmentations.append(cv2.flip(image_uint8, 1))  # Horizontal flip\n",
    "        \n",
    "        return augmentations\n",
    "    \n",
    "    def visualize_preprocessing_steps(self, image_path, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize each step of the preprocessing pipeline\n",
    "        \"\"\"\n",
    "        original = self.load_image(image_path)\n",
    "        if original is None:\n",
    "            return\n",
    "        \n",
    "        steps = {\n",
    "            'Original': original,\n",
    "            'Brain Extracted': self.extract_brain_region(original),\n",
    "            'Denoised': self.medical_denoise(original),\n",
    "            'Contrast Enhanced': self.advanced_contrast_enhancement(original),\n",
    "        }\n",
    "        \n",
    "        # Apply full pipeline for final result\n",
    "        final = self.comprehensive_preprocessing(image_path, save_quality_metrics=False)\n",
    "        if final is not None:\n",
    "            steps['Final Multi-scale'] = (final[:,:,0] * 255).astype(np.uint8)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for idx, (step_name, step_image) in enumerate(steps.items()):\n",
    "            if idx < len(axes):\n",
    "                axes[idx].imshow(step_image, cmap='gray')\n",
    "                axes[idx].set_title(step_name)\n",
    "                axes[idx].axis('off')\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for idx in range(len(steps), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def print_quality_report(self):\n",
    "        \"\"\"Print quality metrics report\"\"\"\n",
    "        if not self.quality_metrics:\n",
    "            print(\"No quality metrics available. Run preprocessing first.\")\n",
    "            return\n",
    "        \n",
    "        psnrs = [metrics['psnr'] for metrics in self.quality_metrics.values()]\n",
    "        ssims = [metrics['ssim'] for metrics in self.quality_metrics.values()]\n",
    "        \n",
    "        print(\"\\n=== PREPROCESSING QUALITY REPORT ===\")\n",
    "        print(f\"Processed Images: {len(self.quality_metrics)}\")\n",
    "        print(f\"Average PSNR: {np.mean(psnrs):.2f} dB\")\n",
    "        print(f\"Average SSIM: {np.mean(ssims):.4f}\")\n",
    "        print(f\"Best PSNR: {np.max(psnrs):.2f} dB\")\n",
    "        print(f\"Worst PSNR: {np.min(psnrs):.2f} dB\")\n",
    "        print(\"====================================\\n\")\n",
    "\n",
    "def detect_label(path):\n",
    "    \"\"\"Label based on folder name\"\"\"\n",
    "    path_str = str(path).lower()\n",
    "    \n",
    "    if \"/no_tumor/\" in path_str:\n",
    "        return \"normal\"\n",
    "    if \"/tumor/\" in path_str:\n",
    "        return \"tumor\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    RAW_DATASET = \"/Users/jeissonparra/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/CT\"\n",
    "    OUTPUT_DATASET = \"/Users/jeissonparra/Library/CloudStorage/OneDrive-FloridaInternationalUniversity/Special_Topics_Advanced_Computational_Methods_in_Health_and_Biomedical_Data/Class_project_Early_detection_of_brain_tumor/CT_enhanced\"\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "    preprocessor = MedicalImagePreprocessor(target_size=(224, 224))\n",
    "    \n",
    "    # Create output directories\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for label in [\"tumor\", \"normal\"]:\n",
    "            os.makedirs(f\"{OUTPUT_DATASET}/{split}/{label}\", exist_ok=True)\n",
    "    \n",
    "    # Supported extensions\n",
    "    valid_ext = [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"]\n",
    "    \n",
    "    # Collect all images\n",
    "    print(\"ðŸ” Scanning for images...\")\n",
    "    all_images = [\n",
    "        p for p in Path(RAW_DATASET).rglob(\"*\")\n",
    "        if p.is_file() and p.suffix.lower() in valid_ext\n",
    "    ]\n",
    "    \n",
    "    print(f\"ðŸ“ Found {len(all_images)} total image files\")\n",
    "    \n",
    "    # Filter and label images\n",
    "    clean_data = []\n",
    "    for img_path in all_images:\n",
    "        label = detect_label(img_path)\n",
    "        if label:\n",
    "            clean_data.append((img_path, label))\n",
    "    \n",
    "    print(f\"âœ… Usable images: {len(clean_data)}\")\n",
    "    print(f\"ðŸ¦  Tumor: {sum(1 for _,l in clean_data if l=='tumor')}\")\n",
    "    print(f\"â¤ï¸ Normal: {sum(1 for _,l in clean_data if l=='normal')}\")\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        print(\"âŒ No images found! Check your RAW_DATASET path and folder structure.\")\n",
    "        return\n",
    "    \n",
    "    # Shuffle and split\n",
    "    random.shuffle(clean_data)\n",
    "    train_split = int(0.7 * len(clean_data))\n",
    "    val_split = int(0.85 * len(clean_data))\n",
    "    \n",
    "    splits = {\n",
    "        \"train\": clean_data[:train_split],\n",
    "        \"val\": clean_data[train_split:val_split],\n",
    "        \"test\": clean_data[val_split:]\n",
    "    }\n",
    "    \n",
    "    # Process & Save with enhanced preprocessing\n",
    "    print(\"\\nðŸš€ Starting enhanced preprocessing...\")\n",
    "    \n",
    "    for split_name, split_data in splits.items():\n",
    "        print(f\"\\nðŸ“‚ Processing {split_name} set ({len(split_data)} images)...\")\n",
    "        \n",
    "        for img_path, label in tqdm(split_data, desc=f\"Processing {split_name}\"):\n",
    "            try:\n",
    "                # Apply comprehensive preprocessing\n",
    "                processed = preprocessor.comprehensive_preprocessing(img_path)\n",
    "                \n",
    "                if processed is not None:\n",
    "                    # Save as numpy array to preserve multi-channel data\n",
    "                    filename = f\"{img_path.stem}_processed.npy\"\n",
    "                    output_path = f\"{OUTPUT_DATASET}/{split_name}/{label}/{filename}\"\n",
    "                    \n",
    "                    # Save both numpy array and image for compatibility\n",
    "                    np.save(output_path, processed)\n",
    "                    \n",
    "                    # Also save as image (first channel)\n",
    "                    image_output_path = output_path.replace('.npy', '.png')\n",
    "                    cv2.imwrite(image_output_path, (processed[:,:,0] * 255).astype(np.uint8))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {img_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Generate quality report\n",
    "    preprocessor.print_quality_report()\n",
    "    \n",
    "    # Visualize preprocessing steps for a few samples\n",
    "    print(\"\\nðŸ“Š Generating preprocessing visualization...\")\n",
    "    sample_images = [img_path for img_path, _ in clean_data[:3]]\n",
    "    for i, sample_path in enumerate(sample_images):\n",
    "        print(f\"Visualizing sample {i+1}: {sample_path.name}\")\n",
    "        preprocessor.visualize_preprocessing_steps(\n",
    "            sample_path, \n",
    "            save_path=f\"preprocessing_steps_sample_{i+1}.png\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Enhanced preprocessing complete!\")\n",
    "    print(f\"ðŸ“ Enhanced dataset saved in: {OUTPUT_DATASET}\")\n",
    "    print(f\"ðŸ“Š Quality metrics available in preprocessor.quality_metrics\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
